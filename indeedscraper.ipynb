{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sgindeed_jobs(i):\n",
    "    url = ('https://sg.indeed.com/jobs?l=singapore&start='+str(i))\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "    print(soup)\n",
    "    job_soup = soup.find(id = \"resultsCol\")\n",
    "\n",
    "    return job_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title(job_elem):\n",
    "    title_elem = job_elem.find('h2',class_='jobTitle')\n",
    "    title = title_elem.text.strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_link(job_elem):\n",
    "    links = job_elem\n",
    "    if links:\n",
    "        link = links['href']\n",
    "        link = 'sg.indeed.com'+link\n",
    "    else:\n",
    "        link = \"\"\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(job_elem):\n",
    "    date_elem = job_elem.find('span',class_ = 'date')\n",
    "    date = date_elem.text.strip()\n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_description(job_elem):\n",
    "    description_elem = job_elem.find('div',class_='job-snippet')\n",
    "    description = description_elem.text.strip()\n",
    "    return description    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(job_elem):\n",
    "    salary_elem = job_elem.find('div',class_='salary-snippet-container')\n",
    "    if salary_elem:\n",
    "        salary = salary_elem.findChildren('span')\n",
    "        salary = salary_elem.text.strip()\n",
    "    else:\n",
    "        salary = \"\"\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_name(job_elem):\n",
    "    company_elem = job_elem.find('span',class_='companyName')\n",
    "    if company_elem:\n",
    "        company = company_elem.text.strip()\n",
    "    else:\n",
    "        company = \"\"\n",
    "    return company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jobs_from(filename = \"job_listings.xls\"):\n",
    "    \n",
    "    jobs_df = pd.DataFrame({'title':[],\n",
    "                        'company name':[],\n",
    "                        'link':[],\n",
    "                        'date listed':[],\n",
    "                        'salary':[],\n",
    "                        'job description':[]})\n",
    "\n",
    "\n",
    "    for i in range(10,201,10):\n",
    "        job_soup = load_sgindeed_jobs(i)\n",
    "   \n",
    "        job_subdf = extract_job_information_indeed(job_soup)\n",
    "        jobs_df = jobs_df.append(job_subdf,ignore_index=True)\n",
    "\n",
    "    print(\"{} listings found online\".format(len(jobs_df)))\n",
    "    jobs_df = jobs_df.dropna(())\n",
    "    \n",
    "    jobs_df.to_excel(filename)\n",
    "    print('After removing incomplete postings, {} new job postings retrieved. Stored in {}.'.format(len(jobs_df),filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_information_indeed(job_soup):\n",
    "    job_elems = job_soup.find_all('div',class_='slider_container')\n",
    "    #print(\"job elems length \", len(job_elems))\n",
    "\n",
    "\n",
    "    titles = []\n",
    "    for job_elem in job_elems:\n",
    "        titles.append(extract_job_title(job_elem))\n",
    "    \n",
    "    companies = []\n",
    "    for job_elem in job_elems:\n",
    "        companies.append(extract_company_name(job_elem))\n",
    "  \n",
    "    links = []\n",
    "    for job_elem in job_elems:\n",
    "        job_elem = job_elem.find_parent('a')\n",
    "        links.append(extract_link(job_elem))\n",
    "  \n",
    "\n",
    "    dates = []\n",
    "    for job_elem in job_elems:\n",
    "        dates.append(extract_date(job_elem))\n",
    "\n",
    "    salaries = []\n",
    "    for job_elem in job_elems:\n",
    "        salaries.append(extract_salary(job_elem))\n",
    "\n",
    "    job_desc = []\n",
    "    for job_elem in job_elems:\n",
    "        job_desc.append(extract_description(job_elem))\n",
    "    \n",
    "    jobs_df = pd.DataFrame({'title':titles,\n",
    "                        'company name': companies,\n",
    "                        'link':links,\n",
    "                        'date listed':dates,\n",
    "                        'salary':salaries,\n",
    "                        'job description': job_desc})\n",
    "    \n",
    "    return jobs_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b3564d50b6ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_jobs_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-0667af9553ba>\u001b[0m in \u001b[0;36mfind_jobs_from\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mjob_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sgindeed_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mjob_subdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_job_information_indeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_soup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mjobs_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjobs_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_subdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-d33c78ae4811>\u001b[0m in \u001b[0;36mextract_job_information_indeed\u001b[0;34m(job_soup)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_job_information_indeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_soup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjob_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'slider_container'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(\"job elems length \", len(job_elems))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "\n",
    "find_jobs_from()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
